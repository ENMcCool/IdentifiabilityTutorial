import time
import numpy as np
import matplotlib.pyplot as plt
import nlopt
from scipy.stats import lognorm, chi2
from scipy.interpolate import UnivariateSpline

# Load packages equivalent to: using Plots, DifferentialEquations, Interpolations, Random, Distributions, NLopt, Dierckx, LaTeXStrings
# In Python we use matplotlib for plotting, nlopt for optimization, scipy.stats for distributions, and scipy.interpolate for splines.
# gr() equivalent is not needed.

a = np.zeros(3)
J = 1.0
D = 1.0
k = 1/10
σ = 1.0/2  # Define parameters

x = np.linspace(0, 20, 21)   # Set up discretisation of truncated domain 0 < x < 20, with uniform mesh spacing of 1.0
xx = np.linspace(0, 20, 201)   # Set up fine discretisation of truncated domain 0 < x < 20, with uniform mesh spacing of 0.1

def model(x, a):
    # Function to return the BVP solution at positions in the vector x 
    y = np.zeros(len(x))
    def c(val):
        # c(x) = a[1]*exp(-x*sqrt(a[3]/a[2]))/sqrt(a[2]*a[3])
        return a[0]*np.exp(-val*np.sqrt(a[2]/a[1]))/np.sqrt(a[1]*a[2])
    for i in range(len(x)):
        y[i] = c(x[i])
    return y

data = np.array([3.898952675812746,
                 2.569825438525737,
                 1.206631819080483,
                 1.3543817108830818,
                 0.6175527058221386,
                 0.30785528929186456,
                 0.13649714414672498,
                 0.6921031114954066,
                 0.271392505145547,
                 0.0945662375934022,
                 0.06039757137011752,
                 0.1338145218277993,
                 0.1529291485263356,
                 0.05189445084962129,
                 0.02756210195622014,
                 0.018066943988933968,
                 0.017710583152626524,
                 0.009164129234587067,
                 0.008075081582671598,
                 0.010557776318846062,
                 0.004853780605374777])
# Fixed data generated by solving the process model and corrupting the solution with multiplicative log‐normal noise with sigma=0.5 

def loglhood(data, a, σ):
    # function to evaluate the loglikelihood of the data stored in the vector data.
    y = model(x, a)  # evaluate the model solution with parameters a = [J, D, k]
    ℓ = 0.0
    # data_dists = [LogNormal(0,σ) for mi in y]; in Python we use lognorm with s=σ and scale=exp(0)=1.
    data_dists = [lognorm(s=σ, scale=1) for mi in y]
    for i in range(len(data_dists)):
        # compute the loglikelihood, here the distribution is dist, and the observations are the ratio between the data and the model solution at each location
        ℓ += np.log(data_dists[i].pdf(data[i] / y[i]))
    return ℓ
    return ℓ

a = np.zeros(3)

def funmle(a):
    # function to optimize for the MLE, this function returns the log-likelihood for the vector of parameters a = (J, D, k)
    return loglhood(data, a, σ)

def Optimise(fun, θ0, lb, ub):
    # Optimize finds the values of parameters theta that maximise the objective function fun with lower bounds lb, and upper bounds ub
    def tomax(theta, grad):
        return fun(theta)
    opt = nlopt.opt(nlopt.LN_NELDERMEAD, len(θ0))
    opt.set_max_objective(tomax)
    opt.set_lower_bounds(lb)
    opt.set_upper_bounds(ub)
    opt.set_maxtime(1*60)
    xopt = opt.optimize(np.array(θ0))
    fopt = opt.last_optimum_value()
    return xopt, fopt

θG = [J, D, k]  # Initial parameter estimates for the iterative optimization solver 
lb = [0, 0, 0]  # lower bounds
ub = [1000, 1000, 1000]  # upper bounds

start = time.time()
xopt, fopt = Optimise(funmle, θG, lb, ub)  # Compute MLE and value of the log-likelihood at the MLE, print the time taken to optimize the solution
print("Time taken: {:.4f} seconds".format(time.time()-start))
Jmle = xopt[0]  # Store MLE
Dmle = xopt[1]  # Store MLE
kmle = xopt[2]  # Store MLE
fmle = fopt    # Store log-likelihood value at the MLE

def cmle(x_val):
    # MLE solution
    return xopt[0]*np.exp(-x_val*np.sqrt(xopt[2]/xopt[1]))/np.sqrt(xopt[1]*xopt[2])

# Plot the MLE solution on the data, Figure 6(a)
plt.figure()
plt.scatter(x, data, c='blue', label='_nolegend_')
plt.plot(xx, cmle(xx), color='red', linewidth=3, label='_nolegend_')
plt.xlabel(r"$x$")
plt.ylabel(r"$U(x)$")
plt.xlim(xx[0]-1, xx[-1]+1)
plt.xticks([0, 5, 10, 15, 20], [r"$0$", r"$5$", r"$10$", r"$15$", r"$20$"])
plt.yticks([0, 1, 2, 3, 4], [r"$0$", r"$1$", r"$2$", r"$3$", r"$4$"])
plt.tick_params(labelsize=12)
plt.show()

df = 1  # degrees of freedom for the asymptotic threshold value for the univariate profile likelihood
llstar = -chi2.ppf(0.95, df) / 2  # log-likelihood threshold for the 95% threshold

def univariateJ(J):
    # Function to compute the univariate profile likelihood for J
    a = np.zeros(2)
    def funJ(a):
        return loglhood(data, np.array([J, a[0], a[1]]), σ)  # evaluate the log-likelihood at a specified value of J
    θG_local = [Dmle, kmle]   # Estimate of the nuisance parameters D, k
    lb_local = [0.0, 0.0]     # Lower bounds of nuisance parameters D, k
    ub_local = [1000.0, 1000.0]  # Upper bounds of nuisance parameters D, k
    xopt_local, fopt_local = Optimise(funJ, θG_local, lb_local, ub_local)
    return fopt_local, xopt_local  # Return the profile log-likelihood and value of the nuisance parameter

def f_J(x):
    return univariateJ(x)[0]  # Define function to compute the profile likelihood

M = 50  # Take a grid of M points to plot the univariate profile likelihood
Jrange = np.linspace(0.2, 3, M)
ff = np.zeros(M)
for i in range(M):
    ff[i] = univariateJ(Jrange[i])[0]  # Compute the profile log-likelihood over the M mesh points

# Plot the normalised profile log-likelihood for J, superimposed with the MLE and 95% threshold
plt.figure()
plt.axhline(y=llstar, color='gold', linewidth=4)
plt.xlabel(r"$J$")
plt.ylabel(r"$\bar{\ell}_p$")
plt.axvline(x=Jmle, color='blue', linewidth=4)
spl = UnivariateSpline(Jrange, ff - np.max(ff), w=np.ones(len(Jrange)), k=1)
spl.set_smoothing_factor(1/100)
yy = spl(Jrange)
plt.plot(Jrange, yy, linewidth=4, color='red')
plt.ylim(-3, 0.1)
plt.xlim(Jrange[0], Jrange[-1])
plt.xticks([1, 2, 3], [r"$1$", r"$2$", r"$3$"])
plt.yticks([0, -1, -2, -3], [r"$0$", r"$-1$", r"$-2$", r"$-3$"])
plt.tick_params(labelsize=12)
plt.show()

def univariateD(D):
    # Function to compute the univariate profile likelihood for D
    a = np.zeros(2)
    def funD(a):
        return loglhood(data, np.array([a[0], D, a[1]]), σ)  # evaluate the log-likelihood at a specified value of D
    θG_local = [Jmle, kmle]  # Estimate of the nuisance parameters J, k
    lb_local = [0.0, 0.0]    # Lower bounds of nuisance parameters J, k
    ub_local = [10.0, 100.0]  # Upper bounds of nuisance parameters J, k
    xopt_local, fopt_local = Optimise(funD, θG_local, lb_local, ub_local)
    return fopt_local, xopt_local  # Return the profile log-likelihood and value of the nuisance parameter

def f_D(x):
    return univariateD(x)[0]  # Define function to compute the profile likelihood

M = 40  # Take a grid of M points to plot the univariate profile likelihood
Drange = np.linspace(0.5, 3, M)
ff_D = np.zeros(M)
for i in range(M):
    ff_D[i] = univariateD(Drange[i])[0]  # Compute the profile log-likelihood over the M mesh points

# Plot the normalised profile log-likelihood for D, superimposed with the MLE and 95% threshold
plt.figure()
plt.axhline(y=llstar, color='gold', linewidth=4)
plt.xlabel(r"$D$")
plt.ylabel(r"$\bar{\ell}_p$")
plt.axvline(x=Dmle, color='blue', linewidth=4)
spl_D = UnivariateSpline(Drange, ff_D - np.max(ff_D), w=np.ones(len(Drange)), k=1)
spl_D.set_smoothing_factor(1/100)
yy_D = spl_D(Drange)
plt.plot(Drange, yy_D, linewidth=4, color='red')
plt.ylim(-3, 0.1)
plt.xlim(Drange[0], Drange[-1])
plt.xticks([1, 2, 3], [r"$1$", r"$2$", r"$3$"])
plt.yticks([0, -1, -2, -3], [r"$0$", r"$-1$", r"$-2$", r"$-3$"])
plt.tick_params(labelsize=12)
plt.show()

def univariatek(k_val):
    # Function to compute the univariate profile likelihood for k
    a = np.zeros(2)
    def funk(a):
        return loglhood(data, np.array([a[0], a[1], k_val]), σ)  # evaluate the log-likelihood at a specified value of k
    θG_local = [Jmle, Dmle]  # Estimate of the nuisance parameters J, D
    lb_local = [0.0, 0.0]   # Lower bounds of nuisance parameters J, D
    ub_local = [1000.0, 1000.0]  # Upper bounds of nuisance parameters J, D
    xopt_local, fopt_local = Optimise(funk, θG_local, lb_local, ub_local)
    return fopt_local, xopt_local  # Return the profile log-likelihood and value of the nuisance parameter

def f_k(x):
    return univariatek(x)[0]  # Define function to compute the profile likelihood

M = 50  # Take a grid of M points to plot the univariate profile likelihood
krange = np.linspace(0.01, 0.60, M)
ff_k = np.zeros(M)
for i in range(M):
    ff_k[i] = univariatek(krange[i])[0]  # Compute the profile log-likelihood over the M mesh points

# Plot the normalised profile log-likelihood for k, superimposed with the MLE and 95% threshold
plt.figure()
plt.axhline(y=llstar, color='gold', linewidth=4)
plt.xlabel(r"$k$")
plt.ylabel(r"$\bar{\ell}_p$")
plt.axvline(x=kmle, color='blue', linewidth=4)
spl_k = UnivariateSpline(krange, ff_k - np.max(ff_k), w=np.ones(len(krange)), k=1)
spl_k.set_smoothing_factor(1/100)
yy_k = spl_k(krange)
plt.plot(krange, yy_k, linewidth=4, color='red')
plt.ylim(-3, 0.1)
plt.xlim(krange[0], krange[-1])
plt.xticks([0.2, 0.4, 0.6], [r"$0.2$", r"$0.4$", r"$0.6$"])
plt.yticks([0, -1, -2, -3], [r"$0$", r"$-1$", r"$-2$", r"$-3$"])
plt.tick_params(labelsize=12)
plt.show()

# Combine plots q1, q2, q3 in a 3-row layout (Figure 6(b)-(d))
fig, axs = plt.subplots(3, 1, figsize=(8, 12))
# q1 subplot
axs[0].axhline(y=llstar, color='gold', linewidth=4)
axs[0].axvline(x=Jmle, color='blue', linewidth=4)
spl = UnivariateSpline(Jrange, ff - np.max(ff), w=np.ones(len(Jrange)), k=1)
spl.set_smoothing_factor(1/100)
axs[0].plot(Jrange, spl(Jrange), linewidth=4, color='red')
axs[0].set_xlabel(r"$J$")
axs[0].set_ylabel(r"$\bar{\ell}_p$")
axs[0].set_xlim(Jrange[0], Jrange[-1])
axs[0].set_ylim(-3, 0.1)
axs[0].set_xticks([1, 2, 3])
axs[0].set_xticklabels([r"$1$", r"$2$", r"$3$"])
axs[0].set_yticks([0, -1, -2, -3])
axs[0].set_yticklabels([r"$0$", r"$-1$", r"$-2$", r"$-3$"])
axs[0].tick_params(labelsize=12)
# q2 subplot
axs[1].axhline(y=llstar, color='gold', linewidth=4)
axs[1].axvline(x=Dmle, color='blue', linewidth=4)
spl_D = UnivariateSpline(Drange, ff_D - np.max(ff_D), w=np.ones(len(Drange)), k=1)
spl_D.set_smoothing_factor(1/100)
axs[1].plot(Drange, spl_D(Drange), linewidth=4, color='red')
axs[1].set_xlabel(r"$D$")
axs[1].set_ylabel(r"$\bar{\ell}_p$")
axs[1].set_xlim(Drange[0], Drange[-1])
axs[1].set_ylim(-3, 0.1)
axs[1].set_xticks([1, 2, 3])
axs[1].set_xticklabels([r"$1$", r"$2$", r"$3$"])
axs[1].set_yticks([0, -1, -2, -3])
axs[1].set_yticklabels([r"$0$", r"$-1$", r"$-2$", r"$-3$"])
axs[1].tick_params(labelsize=12)
# q3 subplot
axs[2].axhline(y=llstar, color='gold', linewidth=4)
axs[2].axvline(x=kmle, color='blue', linewidth=4)
spl_k = UnivariateSpline(krange, ff_k - np.max(ff_k), w=np.ones(len(krange)), k=1)
spl_k.set_smoothing_factor(1/100)
axs[2].plot(krange, spl_k(krange), linewidth=4, color='red')
axs[2].set_xlabel(r"$k$")
axs[2].set_ylabel(r"$\bar{\ell}_p$")
axs[2].set_xlim(krange[0], krange[-1])
axs[2].set_ylim(-3, 0.1)
axs[2].set_xticks([0.2, 0.4, 0.6])
axs[2].set_xticklabels([r"$0.2$", r"$0.4$", r"$0.6$"])
axs[2].set_yticks([0, -1, -2, -3])
axs[2].set_yticklabels([r"$0$", r"$-1$", r"$-2$", r"$-3$"])
axs[2].tick_params(labelsize=12)
plt.tight_layout()
plt.show()

# Combine the plots p1 and q4 in a 1x2 layout (Figure 6)
fig = plt.figure(constrained_layout=True, figsize=(16, 8))
gs_master = fig.add_gridspec(1, 2)
# Left panel: p1 (data with MLE solution)
ax_left = fig.add_subplot(gs_master[0, 0])
ax_left.scatter(x, data, c='blue')
ax_left.plot(xx, cmle(xx), color='red', linewidth=3)
ax_left.set_xlabel(r"$x$")
ax_left.set_ylabel(r"$U(x)$")
ax_left.set_xlim(xx[0]-1, xx[-1]+1)
ax_left.set_xticks([0, 5, 10, 15, 20])
ax_left.set_xticklabels([r"$0$", r"$5$", r"$10$", r"$15$", r"$20$"])
ax_left.set_yticks([0, 1, 2, 3, 4])
ax_left.set_yticklabels([r"$0$", r"$1$", r"$2$", r"$3$", r"$4$"])
ax_left.tick_params(labelsize=12)
# Right panel: q4 (the three profile likelihood plots)
gs_right = gs_master[0, 1].subgridspec(3, 1)
ax_q1 = fig.add_subplot(gs_right[0])
ax_q2 = fig.add_subplot(gs_right[1])
ax_q3 = fig.add_subplot(gs_right[2])
# q1 in right panel
ax_q1.axhline(y=llstar, color='gold', linewidth=4)
ax_q1.axvline(x=Jmle, color='blue', linewidth=4)
spl = UnivariateSpline(Jrange, ff - np.max(ff), w=np.ones(len(Jrange)), k=1)
spl.set_smoothing_factor(1/100)
ax_q1.plot(Jrange, spl(Jrange), linewidth=4, color='red')
ax_q1.set_xlabel(r"$J$")
ax_q1.set_ylabel(r"$\bar{\ell}_p$")
ax_q1.set_xlim(Jrange[0], Jrange[-1])
ax_q1.set_ylim(-3, 0.1)
ax_q1.set_xticks([1, 2, 3])
ax_q1.set_xticklabels([r"$1$", r"$2$", r"$3$"])
ax_q1.set_yticks([0, -1, -2, -3])
ax_q1.set_yticklabels([r"$0$", r"$-1$", r"$-2$", r"$-3$"])
ax_q1.tick_params(labelsize=12)
# q2 in right panel
ax_q2.axhline(y=llstar, color='gold', linewidth=4)
ax_q2.axvline(x=Dmle, color='blue', linewidth=4)
spl_D = UnivariateSpline(Drange, ff_D - np.max(ff_D), w=np.ones(len(Drange)), k=1)
spl_D.set_smoothing_factor(1/100)
ax_q2.plot(Drange, spl_D(Drange), linewidth=4, color='red')
ax_q2.set_xlabel(r"$D$")
ax_q2.set_ylabel(r"$\bar{\ell}_p$")
ax_q2.set_xlim(Drange[0], Drange[-1])
ax_q2.set_ylim(-3, 0.1)
ax_q2.set_xticks([1, 2, 3])
ax_q2.set_xticklabels([r"$1$", r"$2$", r"$3$"])
ax_q2.set_yticks([0, -1, -2, -3])
ax_q2.set_yticklabels([r"$0$", r"$-1$", r"$-2$", r"$-3$"])
ax_q2.tick_params(labelsize=12)
# q3 in right panel
ax_q3.axhline(y=llstar, color='gold', linewidth=4)
ax_q3.axvline(x=kmle, color='blue', linewidth=4)
spl_k = UnivariateSpline(krange, ff_k - np.max(ff_k), w=np.ones(len(krange)), k=1)
spl_k.set_smoothing_factor(1/100)
ax_q3.plot(krange, spl_k(krange), linewidth=4, color='red')
ax_q3.set_xlabel(r"$k$")
ax_q3.set_ylabel(r"$\bar{\ell}_p$")
ax_q3.set_xlim(krange[0], krange[-1])
ax_q3.set_ylim(-3, 0.1)
ax_q3.set_xticks([0.2, 0.4, 0.6])
ax_q3.set_xticklabels([r"$0.2$", r"$0.4$", r"$0.6$"])
ax_q3.set_yticks([0, -1, -2, -3])
ax_q3.set_yticklabels([r"$0$", r"$-1$", r"$-2$", r"$-3$"])
ax_q3.tick_params(labelsize=12)
plt.show()
